actual_n_map$rate[actual_n_map$year == 1985] = predicted_sd_II_1985
actual_n_map$rate[actual_n_map$year == 1988] = predicted_sd_II_1988
hardcoded_bins = round(seq(min(actual_n_map$rate), max(actual_n_map$rate), length.out = 8), 2)
plt1 <- case_count_plot_1_year(actual_n_map, years_to_plot[1], hardcoded_bins, title = "Improper_1_typeII\n std predicted rate\n 1979")
plt2 <- case_count_plot_1_year(actual_n_map, years_to_plot[2], hardcoded_bins, title = "Improper_1_typeII\n std predicted rate\n 1982")
plt3 <- case_count_plot_1_year(actual_n_map, years_to_plot[3], hardcoded_bins, title = "Improper_1_typeII\n std predicted rate\n 1985")
plt4 <- case_count_plot_1_year(actual_n_map, years_to_plot[4], hardcoded_bins, title = "Improper_1_typeII\n std predicted rate\n 1988")
#Save as 13 by 3.5
ggarrange(plt1, plt2, plt3, plt4, ncol = 4, nrow = 1,
common.legend = TRUE, legend = "right")
#Find predicted values for Proper_onlyInt
predicted_proper_1979 = rep(0, n)
predicted_sd_proper_1979 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[1, i])
predicted_proper_1979[i] <- pred_rate * 1E5
predicted_sd_proper_1979[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[1, i])
}
predicted_proper_1982 = rep(0, n)
predicted_sd_proper_1982 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[4, i])
predicted_proper_1982[i] <- pred_rate * 1E5
predicted_sd_proper_1982[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[4, i])
}
predicted_proper_1985 = rep(0, n)
predicted_sd_proper_1985 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[7, i])
predicted_proper_1985[i] <- pred_rate * 1E5
predicted_sd_proper_1985[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[7, i])
}
predicted_proper_1988 = rep(0, n)
predicted_sd_proper_1988 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[10, i])
predicted_proper_1988[i] <- pred_rate * 1E5
predicted_sd_proper_1988[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[10, i])
}
actual_n_map$rate[actual_n_map$year == 1979] = predicted_proper_1979
actual_n_map$rate[actual_n_map$year == 1982] = predicted_proper_1982
actual_n_map$rate[actual_n_map$year == 1985] = predicted_proper_1985
actual_n_map$rate[actual_n_map$year == 1988] = predicted_proper_1988
plt1 <- case_count_plot_1_year(actual_n_map, years_to_plot[1], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1979")
plt2 <- case_count_plot_1_year(actual_n_map, years_to_plot[2], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1982")
plt3 <- case_count_plot_1_year(actual_n_map, years_to_plot[3], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1985")
plt4 <- case_count_plot_1_year(actual_n_map, years_to_plot[4], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1988")
#Save as 13 by 3.5
ggarrange(plt1, plt2, plt3, plt4, ncol = 4, nrow = 1,
common.legend = TRUE, legend = "right")
years_to_plot = c(1979, 1982, 1985, 1988)
years_to_plot_id_pred = c(1, 4, 7, 10)
actual = ohio_df
#Extract true values for years_to_plot
if(actual$year[1]==1){
actual$year = actual$year + (1968 - 1)
}
actual <- actual[actual$year %in% years_to_plot, ]
#Merge true values with map
actual_n_map <- merge(ohio_map, actual,
by.x = c("NAME"), by.y = c("name"),
all = T, suffixes = T)
actual_n_map$rate <- actual_n_map$rate * 1E5
#Hardcoded bins
hardcoded_bins = seq(min(actual_n_map$rate) - 0.5,
max(actual_n_map$rate) + 0.5,
length.out = 8)
hardcoded_bins = round(hardcoded_bins, 0)
#Find predicted values for Proper_onlyInt
predicted_proper_1979 = rep(0, n)
predicted_sd_proper_1979 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[1, i])
predicted_proper_1979[i] <- pred_rate * 1E5
predicted_sd_proper_1979[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[1, i])
}
predicted_proper_1982 = rep(0, n)
predicted_sd_proper_1982 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[4, i])
predicted_proper_1982[i] <- pred_rate * 1E5
predicted_sd_proper_1982[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[4, i])
}
predicted_proper_1985 = rep(0, n)
predicted_sd_proper_1985 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[7, i])
predicted_proper_1985[i] <- pred_rate * 1E5
predicted_sd_proper_1985[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[7, i])
}
predicted_proper_1988 = rep(0, n)
predicted_sd_proper_1988 = rep(0, n)
for(i in 1:n){
pred_rate = find_mean_marginal(proper_interaction_predicted[10, i])
predicted_proper_1988[i] <- pred_rate * 1E5
predicted_sd_proper_1988[i] <- find_sd_per_100000_marginal(proper_interaction_predicted[10, i])
}
actual_n_map$rate[actual_n_map$year == 1979] = predicted_proper_1979
actual_n_map$rate[actual_n_map$year == 1982] = predicted_proper_1982
actual_n_map$rate[actual_n_map$year == 1985] = predicted_proper_1985
actual_n_map$rate[actual_n_map$year == 1988] = predicted_proper_1988
plt1 <- case_count_plot_1_year(actual_n_map, years_to_plot[1], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1979")
plt2 <- case_count_plot_1_year(actual_n_map, years_to_plot[2], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1982")
plt3 <- case_count_plot_1_year(actual_n_map, years_to_plot[3], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1985")
plt4 <- case_count_plot_1_year(actual_n_map, years_to_plot[4], hardcoded_bins, title = "Proper_onlyInt\n predicted rate 1988")
#Save as 13 by 3.5
ggarrange(plt1, plt2, plt3, plt4, ncol = 4, nrow = 1,
common.legend = TRUE, legend = "right")
actual_n_map$rate[actual_n_map$year == 1979] = predicted_sd_proper_1979
actual_n_map$rate[actual_n_map$year == 1982] = predicted_sd_proper_1982
actual_n_map$rate[actual_n_map$year == 1985] = predicted_sd_proper_1985
actual_n_map$rate[actual_n_map$year == 1988] = predicted_sd_proper_1988
hardcoded_bins = round(seq(min(actual_n_map$rate), max(actual_n_map$rate), length.out = 8), 2)
plt1 <- case_count_plot_1_year(actual_n_map, years_to_plot[1], hardcoded_bins, title = "Proper_onlyInt\n std per 100000 of\n one-step prediction 1979")
plt2 <- case_count_plot_1_year(actual_n_map, years_to_plot[2], hardcoded_bins, title = "Proper_onlyInt\n std per 100000 of\n one-step prediction 1982")
plt3 <- case_count_plot_1_year(actual_n_map, years_to_plot[3], hardcoded_bins, title = "Proper_onlyInt\n std per 100000 of\n one-step prediction 1985")
plt4 <- case_count_plot_1_year(actual_n_map, years_to_plot[4], hardcoded_bins, title = "Proper_onlyInt\n std per 100000 of\n one-step prediction 1988")
#Save as 13 by 3.5
ggarrange(plt1, plt2, plt3, plt4, ncol = 4, nrow = 1,
common.legend = TRUE, legend = "right")
plt1 <- case_count_plot_1_year(actual_n_map, years_to_plot[1], hardcoded_bins, title = "Proper_onlyInt\n std predicted rate\n 1979")
plt2 <- case_count_plot_1_year(actual_n_map, years_to_plot[2], hardcoded_bins, title = "Proper_onlyInt\n std predicted rate\n 1982")
plt3 <- case_count_plot_1_year(actual_n_map, years_to_plot[3], hardcoded_bins, title = "Proper_onlyInt\n std predicted rate\n 1985")
plt4 <- case_count_plot_1_year(actual_n_map, years_to_plot[4], hardcoded_bins, title = "Proper_onlyInt\n std predicted rate\n 1988")
#Save as 13 by 3.5
ggarrange(plt1, plt2, plt3, plt4, ncol = 4, nrow = 1,
common.legend = TRUE, legend = "right")
#Want to extract county with highest average rate, lowest average,
#the one with largest range, and one random one
max_avg_rate <- mean(ohio_df[ohio_df$county == 1, ]$rate)
id_max_avg_rate <- 1
min_avg_rate <- mean(ohio_df[ohio_df$county == 1, ]$rate)
id_min_avg_rate <- 1
max_range_rate <- max(ohio_df[ohio_df$county == 1, ]$rate) - min(ohio_df[ohio_df$county == 1, ]$rate)
id_max_range_rate <- 1
for(i in 2:n){
county = ohio_df[ohio_df$county == i, ]
curr_avg_rate <- mean(county$rate)
curr_range <- max(county$rate) - min(county$rate)
if(curr_avg_rate > max_avg_rate){
max_avg_rate = curr_avg_rate
id_max_avg_rate = i
}
if(curr_avg_rate < min_avg_rate){
min_avg_rate = curr_avg_rate
id_min_avg_rate = i
}
if(curr_range > max_range_rate){
max_range_rate = curr_range
id_max_range_rate = i
}
}
years_predicted_on <- 12:21
#Extract deaths from years which we predicted on
values_predicted_on <- ohio_df$deaths[ohio_df$year %in% years_predicted_on]
#Extract population in years predicted on
pop_in_values_pred_on <- ohio_df$pop_at_risk[ohio_df$year %in% years_predicted_on]
#Need to add one more to pop-in-values
pop_in_values_pred_on = c(pop_in_values_pred_on,
pop_in_values_pred_on[(length(pop_in_values_pred_on) - n + 1):length(pop_in_values_pred_on)])
counties = c(id_max_avg_rate, id_min_avg_rate, 75, 3)
#Do the same but for predicted values
#Save as 12 by 9
predicted_vs_true_select_counties(base_predicted,
II_predicted,
proper_interaction_predicted,
pop_in_values_pred_on,
values_predicted_on,
counties)
#Want to extract county with highest average rate, lowest average,
#the one with largest range, and one random one
max_avg_rate <- mean(ohio_df[ohio_df$county == 1, ]$rate)
id_max_avg_rate <- 1
min_avg_rate <- mean(ohio_df[ohio_df$county == 1, ]$rate)
id_min_avg_rate <- 1
max_range_rate <- max(ohio_df[ohio_df$county == 1, ]$rate) - min(ohio_df[ohio_df$county == 1, ]$rate)
id_max_range_rate <- 1
for(i in 2:n){
county = ohio_df[ohio_df$county == i, ]
curr_avg_rate <- mean(county$rate)
curr_range <- max(county$rate) - min(county$rate)
if(curr_avg_rate > max_avg_rate){
max_avg_rate = curr_avg_rate
id_max_avg_rate = i
}
if(curr_avg_rate < min_avg_rate){
min_avg_rate = curr_avg_rate
id_min_avg_rate = i
}
if(curr_range > max_range_rate){
max_range_rate = curr_range
id_max_range_rate = i
}
}
counties = c(id_max_avg_rate, id_min_avg_rate, 50, 4)
#Produces plot of fitted vs true for
# first frame: county w. largest average rate
# second frame: county w. smallest average rate
# third frame: county w. largest range in rate
# fourth frame: a random county
# save pdf: 12 by 9
select_county_timeseries(ohio_df,
RW1_ICAR_fit,
RW1_ICAR_IV_fit,
proper_interaction_fit,
counties,
n,
T)
source("utilities.R")
#Produces plot of fitted vs true for
# first frame: county w. largest average rate
# second frame: county w. smallest average rate
# third frame: county w. largest range in rate
# fourth frame: a random county
# save pdf: 12 by 9
select_county_timeseries(ohio_df,
RW1_ICAR_fit,
RW1_ICAR_IV_fit,
proper_interaction_fit,
counties,
n,
T)
source("utilities.R")
#Produces plot of fitted vs true for
# first frame: county w. largest average rate
# second frame: county w. smallest average rate
# third frame: county w. largest range in rate
# fourth frame: a random county
# save pdf: 12 by 9
select_county_timeseries(ohio_df,
RW1_ICAR_fit,
RW1_ICAR_IV_fit,
proper_interaction_fit,
counties,
n,
T)
#Plot spatial effects Proper vs improper 8 by 3 (was 7.5 by 3.5)
plot_spatial_effects(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
source("utilities.R")
#Plot spatial effects Proper vs improper 8 by 3 (was 7.5 by 3.5)
plot_spatial_effects(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
source("utilities.R")
#Plot spatial effects Proper vs improper 7.5 by 3.5 (was 7.5 by 3.5)
plot_spatial_effects(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
#8 by 3
plot_spatial_std(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
source("utilities.R")
#8 by 3
plot_spatial_std(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
source("utilities.R")
#8 by 3
plot_spatial_std(RW1_ICAR_fit,
proper_base_fit,
ohio_map,
n)
#Plot heatmaps of first year fitted rate
fitted_values_base_y1 <- RW1_ICAR_fit$summary.fitted.values$mean[1:(88)] * 1E5
fitted_values_improperIV_y1 <- RW1_ICAR_IV_fit$summary.fitted.values$mean[1:(88)] *1E5
#Have to sort?
proper_fitted_sorted <- sort_proper_fitted(proper_interaction_fit$summary.fitted.values, n, T)
fitted_values_proper_int_y1 <- proper_fitted_sorted$mean[1:(88)] * 1E5
min_base_y1 <- min(fitted_values_base_y1); max_base_y1 <- max(fitted_values_base_y1)
min_IV_y1 <- min(fitted_values_improperIV_y1); max_IV_y1 <- max(fitted_values_improperIV_y1)
min_proper_y1 <- min(fitted_values_proper_int_y1); max_proper_y1 <- max(fitted_values_proper_int_y1)
min_all = min(c(min_base_y1, min_IV_y1, min_proper_y1)); max_all = max(c(max_base_y1, max_IV_y1, max_proper_y1))
hardcoded_bins = seq(min_all - 0.5,
max_all + 0.5,
length.out = 8)
hardcoded_bins = round(hardcoded_bins, 0)
base_map <- ohio_map
base_map$rate <- fitted_values_base_y1; base_map$year = rep(1968, 88)
p1 <- case_count_plot_1_year(base_map, 1968, hardcoded_bins, title = "Improper_1_noInt\n Fitted rate 1968")
IV_map <- ohio_map
IV_map$rate <- fitted_values_improperIV_y1; IV_map$year = rep(1968, 88)
p2 <- case_count_plot_1_year(IV_map, 1968, hardcoded_bins, title = "Improper_1_typeIV\n Fitted rate 1968")
proper_map <- ohio_map
proper_map$rate <- fitted_values_proper_int_y1; proper_map$year = rep(1968, 88)
p3 <- case_count_plot_1_year(proper_map, 1968, hardcoded_bins, title = "Proper_onlyInt\n Fitted rate 1968")
ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
common.legend = TRUE, legend = "right")
base_map <- ohio_map
base_map$rate <- fitted_values_base_y1; base_map$year = rep(1968, 88)
p1 <- case_count_plot_1_year(base_map, 1968, hardcoded_bins, title = "Improper_1_noInt\n Posterior mean rate 1968")
IV_map <- ohio_map
IV_map$rate <- fitted_values_improperIV_y1; IV_map$year = rep(1968, 88)
p2 <- case_count_plot_1_year(IV_map, 1968, hardcoded_bins, title = "Improper_1_typeIV\n Posterior mean rate 1968")
proper_map <- ohio_map
proper_map$rate <- fitted_values_proper_int_y1; proper_map$year = rep(1968, 88)
p3 <- case_count_plot_1_year(proper_map, 1968, hardcoded_bins, title = "Proper_onlyInt\n Posterior mean rate 1968")
ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
common.legend = TRUE, legend = "right")
#Plot heatmap of relative difference in fitted rate from the first to the last year
fitted_values_base_y2 <- RW1_ICAR_fit$summary.fitted.values$mean[(20 * 88 + 1):(21 * 88)] * 1E5/fitted_values_base_y1
fitted_values_improperIV_y2 <- RW1_ICAR_IV_fit$summary.fitted.values$mean[(20 * 88 + 1):(21 * 88)] *1E5/fitted_values_improperIV_y1
#Have to sort?
proper_fitted_sorted <- sort_proper_fitted(proper_interaction_fit$summary.fitted.values, n, T)
fitted_values_proper_int_y2 <- proper_fitted_sorted$mean[(20 * 88 + 1):(21 * 88)] * 1E5/fitted_values_proper_int_y1
min_base_y2 <- min(fitted_values_base_y2); max_base_y2 <- max(fitted_values_base_y2)
min_IV_y2 <- min(fitted_values_improperIV_y2); max_IV_y2 <- max(fitted_values_improperIV_y2)
min_proper_y2 <- min(fitted_values_proper_int_y2); max_proper_y2 <- max(fitted_values_proper_int_y2)
min_all = min(c(min_base_y2, min_IV_y2, min_proper_y2)); max_all = max(c(max_base_y2, max_IV_y2, max_proper_y2))
hardcoded_bins = seq(min_all,
max_all,
length.out = 8)
hardcoded_bins = round(hardcoded_bins, 2)
base_map <- ohio_map
base_map$rate <- fitted_values_base_y2; base_map$year = rep(1988, 88)
p1 <- case_count_plot_1_year(base_map, 1988, hardcoded_bins, title = "Improper_1_noInt\n Relative change in fitted rate\n from 1968 to 1988")
IV_map <- ohio_map
IV_map$rate <- fitted_values_improperIV_y2; IV_map$year = rep(1988, 88)
p2 <- case_count_plot_1_year(IV_map, 1988, hardcoded_bins, title = "Improper_1_typeIV\n Relative change in fitted rate\n from 1968 to 1988")
proper_map <- ohio_map
proper_map$rate <- fitted_values_proper_int_y2; proper_map$year = rep(1988, 88)
p3 <- case_count_plot_1_year(proper_map, 1988, hardcoded_bins, title = "Proper_onlyInt\n Relative change in fitted rate\n from 1968 to 1988")
#Save as 11.25 by 3.5: all_counties_relative_change_to_1988
ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
common.legend = TRUE, legend = "right")
base_map <- ohio_map
base_map$rate <- fitted_values_base_y2; base_map$year = rep(1988, 88)
p1 <- case_count_plot_1_year(base_map, 1988, hardcoded_bins, title = "Improper_1_noInt\n Relative change in posterior mean\n rate from 1968 to 1988")
IV_map <- ohio_map
IV_map$rate <- fitted_values_improperIV_y2; IV_map$year = rep(1988, 88)
p2 <- case_count_plot_1_year(IV_map, 1988, hardcoded_bins, title = "Improper_1_typeIV\n Relative change in posterior mean\n rate from 1968 to 1988")
proper_map <- ohio_map
proper_map$rate <- fitted_values_proper_int_y2; proper_map$year = rep(1988, 88)
p3 <- case_count_plot_1_year(proper_map, 1988, hardcoded_bins, title = "Proper_onlyInt\n Relative change in posterior mean\n rate from 1968 to 1988")
#Save as 11.25 by 3.5: all_counties_relative_change_to_1988
ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
common.legend = TRUE, legend = "right")
base_map <- ohio_map
base_map$rate <- fitted_values_base_y2; base_map$year = rep(1988, 88)
p1 <- case_count_plot_1_year(base_map, 1988, hardcoded_bins, title = "Improper_1_noInt\n Relative change in posterior\n mean rate from 1968 to 1988")
IV_map <- ohio_map
IV_map$rate <- fitted_values_improperIV_y2; IV_map$year = rep(1988, 88)
p2 <- case_count_plot_1_year(IV_map, 1988, hardcoded_bins, title = "Improper_1_typeIV\n Relative change in posterior\n mean rate from 1968 to 1988")
proper_map <- ohio_map
proper_map$rate <- fitted_values_proper_int_y2; proper_map$year = rep(1988, 88)
p3 <- case_count_plot_1_year(proper_map, 1988, hardcoded_bins, title = "Proper_onlyInt\n Relative change in posterior\n mean rate from 1968 to 1988")
#Save as 11.25 by 3.5: all_counties_relative_change_to_1988
ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
common.legend = TRUE, legend = "right")
test <- function(x){
return(1/2 * x**(-1.5) * exp(-x**(-0.5)))
}
for(x in seq(1, 100, length.out = 10)){
print(test(x))
}
10**(-2)
10**(-0.5)
test(0.1)
test(0.01)
test(0.0001)
10/2 * exp(-10)
10/2 * (0.5)**(-1.5) * exp(-10*0.5**(-0.5))
10/2 * (3)**(-1.5) * exp(-10*3**(-0.5))
#Clear environment
rm(list = ls())
#Load libraries
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
library(gridExtra)
library(ggpubr)
library(roahd)
#Set working directory if not correct
if(getwd() != "C:/Users/joste/Documents/H2023/Code/Prosjektoppgave"){
setwd("H2023/Code/Prosjektoppgave/")
}
source("utilities.R")
#Load data
ohio_df <- read.csv("ohio_df.csv")
#read the shapefile of ohio
ohio_map  <- read_sf('./fe_2007_39_county')[ ,c("geometry", "NAME")]
ohio_map <- ohio_map[order(ohio_map$NAME), ]
#Get number of counties (n) and number of years (T)
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
#Plot dependency structure of Ohio
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
plot(st_geometry(ohio_map), border = "grey")
plot.nb(nb, st_geometry(ohio_map), add = TRUE)
#Start by calculating mean and std. of rate for each county
ohio_map$mean_rate <- rep(0, n)  #Initialize to zero
ohio_map$sd_rate <- rep(0, n)  #Initialize to zero
for(county_name in ohio_df$name){ #Iterate over all the counties
#Extract values for county 'county_name'
temp <- ohio_df[ohio_df$name == county_name, ]
#Calculate mean and standard deviation of rate * 100 000 for that county
ohio_map$mean_rate[ohio_map$NAME == county_name] = mean(temp$rate * 1E5)
ohio_map$sd_rate[ohio_map$NAME == county_name] = sd(temp$rate * 1E5)
}
scale_col = heat.colors(30, rev=TRUE) #Divide color gradient into 30
scale = scale_col[c(3,10,13,18,21,24,27,30)] #Select color scale to be more red
#Create heatmap of mean rate pr. 100 000
mean_rate_plot <- ggplot(data = ohio_map) +
geom_sf(aes(fill = mean_rate), #Plots rate per 100 000
alpha = 1,
color="black") + ggtitle("Average observed rate\n per 100 000") +
theme(plot.title = element_text(size = 15),
axis.title.x = element_blank(), #Remove axis and background grid
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.background = element_blank(),
plot.margin =  unit(c(0, 0, 0, 0), "inches"),
legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
legend.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
panel.spacing = unit(1, 'lines')) +
guides(fill=guide_legend(title=NULL, reverse = TRUE, label.position = "right")) + #Remove colorbar title
binned_scale( #Scaling the color
aesthetics = "fill",
scale_name = "gradientn",
palette = function(x) c(scale),
labels = function(x){x},
guide = "colorscale")
sd_rate_plot <- ggplot(data = ohio_map) +
geom_sf(aes(fill = sd_rate), #Plots cases per thousand
alpha = 1,
color="black") + ggtitle("Empirical standard deviation of\n observed rate per 100 000") +
theme(plot.title = element_text(size = 15),
axis.title.x = element_blank(), #Remove axis and background grid
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.background = element_blank(),
plot.margin =  unit(c(0, 0, 0, 0), "inches"),
legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
legend.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
panel.spacing = unit(1, 'lines')) +
guides(fill=guide_legend(title=NULL, reverse = TRUE, label.position = "right")) + #Remove colorbar title
binned_scale( #Scaling the color
aesthetics = "fill",
scale_name = "gradientn",
palette = function(x) c(scale),
labels = function(x){x},
guide = "colorscale")
ggarrange(mean_rate_plot, sd_rate_plot,
common.legend = FALSE)
#Calculate rate per 100 000
ohio_df$rate <- ohio_df$rate * 1E5
#Transform data to functional data format (only for calculating depth measures)
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$name == unique(ohio_df$name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$name)[2:length(unique(ohio_df$name))]){
temp_ = ohio_df[ohio_df$name == county, ]
temp_data = rbind(temp_data, temp_$rate)
}
fdata <- fData(grid, temp_data)
#Calculate the median curve by way of modified band depth
median_curve = data.frame(
median_curve = median_fData(fdata, type = "MBD")$values[1, ],
year = grid)
#Plot the functional data (each county has its own curve)
#along with the depth median to see potential temporal trend in data
ohio_df$county <- ohio_df$name
theme_set(theme_bw())
ggplot(data = ohio_df,
aes(x = year,
y = rate,
group = county,
color = county),
show.legend = FALSE) +
theme(legend.position="none") +
geom_line() +
geom_line(data = median_curve,
aes(x = year, y = median_curve),
col = 'black', lwd = 3) +
xlab("year") + ylab("Observed rate per 100 000")
#Clear environment
rm(list = ls())
#Load necessary libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
library(gridExtra)
library(ggpubr)
library(latex2exp)
library(tables)
#Set working directory
if(getwd() != "C:/Users/joste/Documents/H2023/Code/Prosjektoppgave"){
setwd("H2023/Code/Prosjektoppgave/")
}
source("utilities.R")
#Load in INLA objects
load("improper_RW1_ICAR_fitted.RData"); load("improper_RW2_ICAR_fitted.RData")
load("proper_fitted.RData"); load("one_step_predictions.RData"); load("one_step_predictions_RW2.RData")
RW1_ICAR_fit$summary.fitted.values$mean
