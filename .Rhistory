ohio_df$rate <- ohio_df$deaths/ohio_df$pop_at_risk
#Find dimensions
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
#structure matrices for random walk 1 and 2
struct_RW1 <- INLA:::inla.rw(n = T, order = 1,
scale.model = FALSE, # set scale.model  = F because we'll scale in the formula
sparse = TRUE)
struct_RW2 <- INLA:::inla.rw(n = T, order = 2,
scale.model = FALSE, # set scale.model  = F because we'll scale in the formula
sparse = TRUE)
#Create ICAR structure matrix
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
matrix4inla <- nb2mat(nb, style="B")
mydiag = rowSums(matrix4inla)
matrix4inla <- -matrix4inla
diag(matrix4inla) <- mydiag
ICAR_structure <- matrix4inla
# quick check: If you coded your ICAR precision matrix correctly, both rows and
# columns will sum to zero
print("rows sum-to-zero:")
print((length(unique(apply(ICAR_structure, 1, sum))) == 1 &
apply(ICAR_structure, 1, sum)[1] == 0))
print("columns sum-to-zero:")
print((length(unique(apply(ICAR_structure, 2, sum))) == 1 &
apply(ICAR_structure, 2, sum)[1] == 0))
#Make the ICAR_structure matrix sparse.
ICAR_structure <- Matrix(ICAR_structure, sparse = TRUE) #Make it sparse
#Add space_time unstructured to ohio_df
ohio_df$space_time_unstructured <- 1:(n *T)
#Save data and precision matrices
write.csv(ohio_df, file = "ohio_df.csv", row.names = FALSE)
writeMM(struct_RW1, file = 'struct_RW1.txt')
writeMM(struct_RW2, file = 'struct_RW2.txt')
writeMM(ICAR_structure, file = 'ICAR_struct.txt')
#How to read the precision matrices
struct_RW1.test = readMM(file='struct_RW1.txt')
struct_RW2.test = readMM(file = 'struct_RW2.txt')
ICAR_structure.test = readMM(file = 'ICAR_struct.txt')
ohio_df.test <- read.csv("ohio_df.csv")
View(ohio_df.test)
#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
library(gridExtra)
library(ggpubr)
library(roahd)
#Load other files
source("functions_plotting_etc.R")
#Load structure matrices
struct_RW1 = readMM(file='struct_RW1.txt')
struct_RW2 = readMM(file = 'struct_RW2.txt')
ICAR_structure = readMM(file = 'ICAR_struct.txt')
#Load data
ohio_df <- read.csv("ohio_df.csv")
#read the shapefile of ohio
ohio_map  <- read_sf('./fe_2007_39_county')[ ,c("geometry", "NAME")]
ohio_map <- ohio_map[order(ohio_map$NAME), ]
#Calculate adjacencies (if needed)
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
#Calculate adjacencies (if needed)
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
#Get number of counties (n) and number of years (T)
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
#Load other files
source("functions_plotting_etc.R")
#Dont know if necessary to merge now at all?
to_plot_potentially <- merge(ohio_map, ohio_df,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#Load other files
source("functions_plotting_etc.R")
p <- case_count_plot_1_year(to_plot_potentially, 1)
p
p$data
p$layers
p$scales$scales
p$scales$get_scales
p$mapping
p$scales
p$scales$scales
p$scales$clone
p$scales$has_scale
p$scales$n
p$scales$non_position_scales
#Dont know if necessary to merge now at all?
to_plot_potentially <- merge(ohio_map, ohio_df,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
#Depth measures over time-series for each county???
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$county_name == unique(ohio_df$county_name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$county_name)[2:length(unique(ohio_df$county_name))]){
temp_ = ohio_df[ohio_df$county_name == county, ]
temp_data = rbind(temp_data, temp_$rate)
#temp_fd = fData(grid, temp_$deaths)
}
fdata <- fData(grid, temp_data)
band_depth = BD(fdata)
modified_band_depth = MBD(fdata)
median_curve = median_fData(fdata, type = "MBD")
plot(fdata)
lines(grid, median_curve$values, lwd = 3)
lines(grid, 0.3 + 1.4 * 10**(-2) * grid, lwd = 2, col = "red")
median_curve$values[1]
median_curve$values[length(median_curve)]''
median_curve$values[length(median_curve$values)]
median_curve$values[T]
#Depth measures over time-series for each county???
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$county_name == unique(ohio_df$county_name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$county_name)[2:length(unique(ohio_df$county_name))]){
temp_ = ohio_df[ohio_df$county_name == county, ]
temp_data = rbind(temp_data, temp_$rate)
#temp_fd = fData(grid, temp_$deaths)
}
fdata <- fData(grid, temp_data)
band_depth = BD(fdata)
modified_band_depth = MBD(fdata)
median_curve = median_fData(fdata, type = "MBD")
#Weak evidence of trend, maybe RW2 performs better
plot(fdata)
lines(grid, median_curve$values, lwd = 3)
lines(grid, (median_curve$values[T] - median_curve$values[1])/T * grid, lwd = 2, col = "red")
#indicates a trend, there is also some weird shapes
#Depth measures over time-series for each county???
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$county_name == unique(ohio_df$county_name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$county_name)[2:length(unique(ohio_df$county_name))]){
temp_ = ohio_df[ohio_df$county_name == county, ]
temp_data = rbind(temp_data, temp_$rate)
#temp_fd = fData(grid, temp_$deaths)
}
fdata <- fData(grid, temp_data)
band_depth = BD(fdata)
modified_band_depth = MBD(fdata)
median_curve = median_fData(fdata, type = "MBD")
#Weak evidence of trend, maybe RW2 performs better
plot(fdata)
lines(grid, median_curve$values, lwd = 3)
lines(grid, (median_curve$values[T] - median_curve$values[1])/2 * grid, lwd = 2, col = "red")
#indicates a trend, there is also some weird shapes
#Depth measures over time-series for each county???
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$county_name == unique(ohio_df$county_name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$county_name)[2:length(unique(ohio_df$county_name))]){
temp_ = ohio_df[ohio_df$county_name == county, ]
temp_data = rbind(temp_data, temp_$rate)
#temp_fd = fData(grid, temp_$deaths)
}
fdata <- fData(grid, temp_data)
band_depth = BD(fdata)
modified_band_depth = MBD(fdata)
median_curve = median_fData(fdata, type = "MBD")
#Weak evidence of trend, maybe RW2 performs better
plot(fdata)
lines(grid, median_curve$values, lwd = 3)
#indicates a trend, there is also some weird shapes
#Temporal
temporal_hyper = list(prec.unstruct = list(prior = 'pc.prec',
param = c(1, 0.01)), #Magic numbers
prec.spatial = list(prior = 'pc.prec',
param = c(1, 0.01)) #Magic numbers
)
#Spatial
spatial_hyper = list(prec.unstruct = list(prior = 'pc.prec',
param = c(1, 0.01)), #Magic numbers
prec.spatial = list(prior = 'pc.prec',
param = c(1, 0.01)) #Magic numbers
)
#Make the base formula (is the overall mean specified correctly here???)
basic_linear_formula <- deaths ~ 1 + f(year,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = struct_RW1,
hyper = temporal_hyper
) +
f(county,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = ICAR_structure,
hyper = spatial_hyper
)
#Make the base formula (is the overall mean specified correctly here???)
basic_linear_formula <- deaths ~ 1 + f(year,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = struct_RW1,
hyper = temporal_hyper
) +
f(county,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = ICAR_structure,
hyper = spatial_hyper
)
#Measure time to do inference
ptm <- Sys.time()
basic_model_fit <- inla(basic_linear_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk, #Is it supposed to be expected or population at risk???
control.compute = list(config = TRUE, # needed if you want to see constraints later
cpo = T,
waic = T), #Needed for model selection
verbose = F #Not T unless want to see a lot of stuff
)
time = Sys.time()-ptm
print(c("Number of constraints (should be 2): ",toString(basic_model_fit$misc$configs$constr$nc)))
print(c("mean CPO:", toString(round(mean(basic_model_fit$cpo$cpo), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(basic_model_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(basic_model_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(basic_model_fit)$cpu.used)))
print(c("Time to compute", toString(time)))
plot(basic_model_fit)
plot(basic_model_fit)
plot(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$mean[1:T],
type = "l", lty = 1, xlab = "Year: t", ylab = "random effect alpha_t") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.025quant'[1:T],
type = "l", lty = 2, col = "red") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.975quant'[1:T],
type = "l", lty = 2, col = "green")
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
knitr::opts_chunk$set(echo = TRUE)
#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
library(gridExtra)
library(ggpubr)
library(roahd)
#Load other files
source("functions_plotting_etc.R")
#Load structure matrices
struct_RW1 = readMM(file='struct_RW1.txt')
struct_RW2 = readMM(file = 'struct_RW2.txt')
ICAR_structure = readMM(file = 'ICAR_struct.txt')
#Load data
ohio_df <- read.csv("ohio_df.csv")
#read the shapefile of ohio
ohio_map  <- read_sf('./fe_2007_39_county')[ ,c("geometry", "NAME")]
ohio_map <- ohio_map[order(ohio_map$NAME), ]
#Calculate adjacencies (if needed)
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
#Get number of counties (n) and number of years (T)
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
#Used for heat map plotting
#bins_hardcoded = c(0, 0.15, 0.3, 0.5, 0.65, 0.8, 1, 1.25)
#Dont know if necessary to merge now at all?
to_plot_potentially <- merge(ohio_map, ohio_df,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
knitr::opts_chunk$set(echo = TRUE)
#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
library(gridExtra)
library(ggpubr)
library(roahd)
#Load other files
source("functions_plotting_etc.R")
#Load structure matrices
struct_RW1 = readMM(file='struct_RW1.txt')
struct_RW2 = readMM(file = 'struct_RW2.txt')
ICAR_structure = readMM(file = 'ICAR_struct.txt')
#Load data
ohio_df <- read.csv("ohio_df.csv")
#read the shapefile of ohio
ohio_map  <- read_sf('./fe_2007_39_county')[ ,c("geometry", "NAME")]
ohio_map <- ohio_map[order(ohio_map$NAME), ]
#Calculate adjacencies (if needed)
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
#Get number of counties (n) and number of years (T)
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
#Used for heat map plotting
#bins_hardcoded = c(0, 0.15, 0.3, 0.5, 0.65, 0.8, 1, 1.25)
#Dont know if necessary to merge now at all?
to_plot_potentially <- merge(ohio_map, ohio_df,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
#Depth measures over time-series for each county???
grid = unique(ohio_df$year)
temp_ = ohio_df[ohio_df$county_name == unique(ohio_df$county_name)[1], ]
temp_data = temp_$rate
for(county in unique(ohio_df$county_name)[2:length(unique(ohio_df$county_name))]){
temp_ = ohio_df[ohio_df$county_name == county, ]
temp_data = rbind(temp_data, temp_$rate)
#temp_fd = fData(grid, temp_$deaths)
}
fdata <- fData(grid, temp_data)
band_depth = BD(fdata)
modified_band_depth = MBD(fdata)
median_curve = median_fData(fdata, type = "MBD")
#Weak evidence of trend, maybe RW2 performs better
plot(fdata)
lines(grid, median_curve$values, lwd = 3)
#indicates a trend, there is also some weird shapes
#Temporal
temporal_hyper = list(prec.unstruct = list(prior = 'pc.prec',
param = c(1, 0.01)), #Magic numbers
prec.spatial = list(prior = 'pc.prec',
param = c(1, 0.01)) #Magic numbers
)
#Spatial
spatial_hyper = list(prec.unstruct = list(prior = 'pc.prec',
param = c(1, 0.01)), #Magic numbers
prec.spatial = list(prior = 'pc.prec',
param = c(1, 0.01)) #Magic numbers
)
#Make the base formula (is the overall mean specified correctly here???)
basic_linear_formula <- deaths ~ 1 + f(year,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = struct_RW1,
hyper = temporal_hyper
) +
f(county,
model = 'bym',
scale.model = T,
constr = T,
rankdef = 1,
graph = ICAR_structure,
hyper = spatial_hyper
)
#Measure time to do inference
ptm <- Sys.time()
basic_model_fit <- inla(basic_linear_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk, #Is it supposed to be expected or population at risk???
control.compute = list(config = TRUE, # needed if you want to see constraints later
cpo = T,
waic = T), #Needed for model selection
verbose = F #Not T unless want to see a lot of stuff
)
time = Sys.time()-ptm
print(c("Number of constraints (should be 2): ",toString(basic_model_fit$misc$configs$constr$nc)))
print(c("mean CPO:", toString(round(mean(basic_model_fit$cpo$cpo), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(basic_model_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(basic_model_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(basic_model_fit)$cpu.used)))
print(c("Time to compute", toString(time)))
plot(basic_model_fit)
plot(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$mean[1:T],
type = "l", lty = 1, xlab = "Year: t", ylab = "random effect alpha_t") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.025quant'[1:T],
type = "l", lty = 2, col = "red") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.975quant'[1:T],
type = "l", lty = 2, col = "green")
#plot(basic_model_fit)
plot(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$mean[1:T],
type = "l", lty = 1, xlab = "Year: t", ylab = "random effect alpha_t") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.025quant'[1:T],
type = "l", lty = 2, col = "red") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.975quant'[1:T],
type = "l", lty = 2, col = "green")
#plot(basic_model_fit)
p <- plot(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$mean[1:T],
type = "l", lty = 1, xlab = "Year: t", ylab = "random effect alpha_t") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.025quant'[1:T],
type = "l", lty = 2, col = "red") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.975quant'[1:T],
type = "l", lty = 2, col = "green")
#plot(basic_model_fit)
p <- plot(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$mean[1:T],
type = "l", lty = 1, xlab = "Year: t", ylab = "random effect alpha_t") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.025quant'[1:T],
type = "l", lty = 2, col = "red") +
lines(basic_model_fit$summary.random$year$ID[1:T],
basic_model_fit$summary.random$year$'0.975quant'[1:T],
type = "l", lty = 2, col = "green")
p
#Extract predictions
#Make dataframe with years and county marked
fitted_values <- data.frame(basic_model_fit$summary.fitted.values$mean)
#This is not actually rate here tho. It is fitted values which is ???
colnames(fitted_values) <- "rate"
fitted_values$year <- ohio_df$year
fitted_values$county <- ohio_df$county
fitted_values$county_name <- ohio_df$county_name
fitted_values$pop_at_risk <- ohio_df$pop_at_risk
#Merge with geometry
fitted_values <- merge(ohio_map, fitted_values,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
plot_all_years(fitted_values, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
################################################################################
#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
################################################################################
#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
library(ggspatial)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
library(gridExtra)
library(ggpubr)
library(roahd)
#Load other files
source("functions_plotting_etc.R")
################################################################################
#Load structure matrices
struct_RW1 = readMM(file='struct_RW1.txt')
struct_RW2 = readMM(file = 'struct_RW2.txt')
ICAR_structure = readMM(file = 'ICAR_struct.txt')
#Load data
ohio_df <- read.csv("ohio_df.csv")
#read the shapefile of ohio
ohio_map  <- read_sf('./fe_2007_39_county')[ ,c("geometry", "NAME")]
ohio_map <- ohio_map[order(ohio_map$NAME), ]
#Calculate adjacencies (if needed)
nb <- spdep::poly2nb(ohio_map, queen = FALSE)
#Get number of counties (n) and number of years (T)
n <- length(unique(ohio_df$county))   # Number of areas
T <- length(unique(ohio_df$year))     # Number of time points
################################################################################
#Explorative plots
#Dont know if necessary to merge now at all?
to_plot_potentially <- merge(ohio_map, ohio_df,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
#From the heatmaps it seems that the rate is increasing over time
plot_all_years(to_plot_potentially, ncol = 7, nrow = 6,
widths = c(2, 0.05, 2, 0.05, 2, 0.05, 2))
