print(c("-sum(log(CPO)): ", toString(round(-sum(log(typeII_fit$cpo$cpo)), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(typeII_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(typeII_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(typeII_fit)$cpu.used)))
print(c("Time: ", time))
#This does not exactly sum to zero...
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$'0.5quant'
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mode
#sum-to-zero constraint be wilding (Is it the right way??? Does it actually do what it is supposed to???)
# - n rows as this interaction makes it so there is a RW for each county independent of each other
# - n * T columns as there are a total of n * T interaction terms (delta_(it))
# - sets A[i, which((0:(n * T - 1))%%n == i - 1)] = 1, as for county i, the interaction (delta_(it))
#     is only dependent on (delta_(i,t+-1)). Therefore the sum-to-zero is over these 88 RWs
# - Constraints: The RW1 in each area needs to sum to 0. Hence in constr.st e is a zero vector
A <- matrix(0, nrow = n, ncol = n * T)
for (i in 1:n) {
#Should it be 0:(n*T - 1)%%(n) == i - 1, used to be 1:(n*T)%%n == i - 1
A[i, which((0:(n * T - 1))%%n == i - 1)] <- 1
#A[i, which((1:(n*T))%%n == i - 1)] <- 1
}
constr.st <- list(A = A, e = rep(0, dim(A)[1]))
scaled_RW_prec <- inla.scale.model(struct_RW1,
list(A = matrix(1, 1, dim(struct_RW1)[1]),
e = 0))
# Kronecker product between RW1 and IID space term
# order matters here! In our data set, the time ordering take precedent over the space ordering
# so we must have the RW on the left and space on the right
R <- scaled_RW_prec %x% diag(n)
typeII_hyperparameters_priors = list(theta=list(prior="pc.prec",
param=c(1,0.01)))
typeII_formula <- update(basic_linear_formula,
~. + f(space_time_unstructured,
model = "generic0",
Cmatrix = R,
extraconstr = constr.st,
rankdef = n,
hyper = typeII_hyperparameters_priors))
ptm <- Sys.time()
typeII_fit <- inla(typeII_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk,
control.compute = list(config = TRUE,
cpo = TRUE,
waic = TRUE),
control.predictor = list(compute = TRUE)
)
time = Sys.time() - ptm
print(c("Number of constraints (should be 2 + 88 = 90): ",toString(typeII_fit$misc$configs$constr$nc)))
print(c("-sum(log(CPO)): ", toString(round(-sum(log(typeII_fit$cpo$cpo)), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(typeII_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(typeII_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(typeII_fit)$cpu.used)))
print(c("Time: ", time))
#This does not exactly sum to zero...
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$'0.5quant'
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mode
#This does not exactly sum to zero...
if(constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e + 1E-10 &
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e - 1E-10){
print("Sum-to-zero constraint holds")
} else{
print("Sum-to-zero constraint does not hold")
}
#This does not exactly sum to zero...
if(constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e + 1E-10 &&
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e - 1E-10){
print("Sum-to-zero constraint holds")
} else{
print("Sum-to-zero constraint does not hold")
}
dim(constr.st$e)
length(constr.st$e)
#This does not exactly sum to zero...
if(constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e + rep(1E-10, length(constr.st$e)) &
constr.st$A %*% typeII_fit$summary.random$space_time_unstructured$mean < constr.st$e - rep(1E-10, length(constr.st$e))){
print("Sum-to-zero constraint holds")
} else{
print("Sum-to-zero constraint does not hold")
}
interaction_mean <- typeII_fit$summary.random$space_time_unstructured$mean
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean == 0, 1, 0)
check_sum_to_zero
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-10 &
constr.st$A %*% interaction_mean < 0 + 1E-10,
0,
1)
check_sum_to_zero
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-4 &
constr.st$A %*% interaction_mean < 0 + 1E-4,
0,
1)
check_sum_to_zero
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-5 &
constr.st$A %*% interaction_mean < 0 + 1E-5,
0,
1)
check_sum_to_zero
print(c("Number of counties for which sum-to-zero did not hold: ", toString(sum(check_sum_to_zero))))
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-10 &
constr.st$A %*% interaction_mean < 0 + 1E-10,
0,
1)
print(c("Number of counties for which sum-to-zero did not hold: ", toString(sum(check_sum_to_zero))))
typeII_fit$summary.random$space_time_unstructured$mean
88%%n
(1:10)%%10
for (i in 1:10) {
}
for(i in 1:10){
print(i - 1)
}
89%%n
View(ohio_df)
1%%n
2%%n
90%%n
#sum-to-zero constraint be wilding (Is it the right way??? Does it actually do what it is supposed to???)
# - n rows as this interaction makes it so there is a RW for each county independent of each other
# - n * T columns as there are a total of n * T interaction terms (delta_(it))
# - sets A[i, which((1:(n * T))%%n == i)] = 1, as for county i, the interaction (delta_(it))
#     is only dependent on (delta_(i,t+-1)). Therefore the sum-to-zero is over these 88 RWs
#     additionaly, set A[n, which(1:(n * T)%%n == 0)] <- 1
# - Constraints: The RW1 in each area needs to sum to 0. Hence in constr.st e is a zero vector
A <- matrix(0, nrow = n, ncol = n * T)
for (i in 1:(n - 1)) {
#Should it be 0:(n*T - 1)%%(n) == i - 1, used to be 1:(n*T)%%n == i - 1
#A[i, which((0:(n * T - 1))%%n == i - 1)] <- 1
#A[i, which((1:(n*T))%%n == i - 1)] <- 1
A[i, which((1:(n * T))%%n == i)] <- 1
}
A[n, which((1:(n * T))%%n == 0)] <- 1
constr.st <- list(A = A, e = rep(0, dim(A)[1]))
scaled_RW_prec <- inla.scale.model(struct_RW1,
list(A = matrix(1, 1, dim(struct_RW1)[1]),
e = 0))
# Kronecker product between RW1 and IID space term
# order matters here! In our data set, the time ordering take precedent over the space ordering
# so we must have the RW on the left and space on the right
R <- scaled_RW_prec %x% diag(n)
typeII_hyperparameters_priors = list(theta=list(prior="pc.prec",
param=c(1,0.01)))
typeII_formula <- update(basic_linear_formula,
~. + f(space_time_unstructured,
model = "generic0",
Cmatrix = R,
extraconstr = constr.st,
rankdef = n,
hyper = typeII_hyperparameters_priors))
ptm <- Sys.time()
typeII_fit <- inla(typeII_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk,
control.compute = list(config = TRUE,
cpo = TRUE,
waic = TRUE),
control.predictor = list(compute = TRUE)
)
time = Sys.time() - ptm
print(c("Number of constraints (should be 2 + 88 = 90): ",toString(typeII_fit$misc$configs$constr$nc)))
print(c("-sum(log(CPO)): ", toString(round(-sum(log(typeII_fit$cpo$cpo)), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(typeII_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(typeII_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(typeII_fit)$cpu.used)))
print(c("Time: ", time))
print(constr.st %*% interaction_mean)
print(constr.st$A %*% interaction_mean)
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-10 &
constr.st$A %*% interaction_mean < 0 + 1E-10,
0,
1)
print(c("Number of counties for which sum-to-zero did not hold: ", toString(sum(check_sum_to_zero))))
constr.st$A
constr.st$A[1, ]
#sum-to-zero constraint be wilding (Is it the right way??? Does it actually do what it is supposed to???)
# - n rows as this interaction makes it so there is a RW for each county independent of each other
# - n * T columns as there are a total of n * T interaction terms (delta_(it))
# - sets A[i, which((1:(n * T))%%n == i)] = 1, as for county i, the interaction (delta_(it))
#     is only dependent on (delta_(i,t+-1)). Therefore the sum-to-zero is over these 88 RWs
#     additionaly, set A[n, which(1:(n * T)%%n == 0)] <- 1
# - Constraints: The RW1 in each area needs to sum to 0. Hence in constr.st e is a zero vector
A <- matrix(0, nrow = n, ncol = n * T)
for (i in 1:(n - 1)) {
#A[i, which((0:(n * T - 1))%%n == i - 1)] <- 1
#A[i, which((1:(n*T))%%n == i - 1)] <- 1
A[i, which((1:(n * T))%%n == i)] <- 1
}
A[n, which((1:(n * T))%%n == 0)] <- 1
constr.st <- list(A = A, e = rep(0, dim(A)[1]))
scaled_RW_prec <- inla.scale.model(struct_RW1,
list(A = matrix(1, 1, dim(struct_RW1)[1]),
e = 0))
# Kronecker product between RW1 and IID space term
# order matters here! In our data set, the time ordering take precedent over the space ordering
# so we must have the RW on the left and space on the right
R <- scaled_RW_prec %x% diag(n)
typeII_hyperparameters_priors = list(theta=list(prior="pc.prec",
param=c(1,0.01)))
typeII_formula <- update(basic_linear_formula,
~. + f(space_time_unstructured,
model = "generic0",
Cmatrix = R,
extraconstr = constr.st,
rankdef = n,
hyper = typeII_hyperparameters_priors))
ptm <- Sys.time()
typeII_fit <- inla(typeII_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk,
control.compute = list(config = TRUE,
cpo = TRUE,
waic = TRUE),
control.predictor = list(compute = TRUE)
)
time = Sys.time() - ptm
print(c("Number of constraints (should be 2 + 88 = 90): ",toString(typeII_fit$misc$configs$constr$nc)))
print(c("-sum(log(CPO)): ", toString(round(-sum(log(typeII_fit$cpo$cpo)), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(typeII_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(typeII_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(typeII_fit)$cpu.used)))
print(c("Time: ", time))
#Check sum-to-zero constraints on interactions
interaction_mean <- typeII_fit$summary.random$space_time_unstructured$mean
print(constr.st$A %*% interaction_mean)
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-10 &
constr.st$A %*% interaction_mean < 0 + 1E-10,
0,
1)
print(c("Number of counties for which sum-to-zero did not hold: ", toString(sum(check_sum_to_zero))))
#save type II cpo
typeII_cpo_summary <- round(-sum(log(typeII_fit$cpo$cpo)), digits = 4)
typeII_cpo_summary
1:n%%n
89:(2*n)%%n
(n+1):(2 * n)%%n
(2*n+1):(3 * n)%%n
source("~/H2023/Code/Prosjektoppgave/first_fits_w_inference.R", echo=TRUE)
#Check sum-to-zero constraints on interactions
interaction_mean <- typeII_fit$summary.random$space_time_unstructured$mean
print(constr.st$A %*% interaction_mean)
typeII_fit$summary.random$space_time_unstructured$mean
typeII_fit$model.random
typeII_fit$size.random
typeII_fit
typeII_fit$summary.spde2.blc
typeII_fit
typeII_fit$.args$debug
typeII_fit$.args$formula
typeII_fit$.args$family
typeII_fit$.args$E
typeII_fit
##################################################
### creating constraint needed for Type III Interaction
A <- matrix(0, nrow = T, ncol = n * T)
for (i in 1:T) {
# The ICAR at each time point needs to sum to 0
A[i, ((i - 1) * n + 1):(i * n)] <- 1
}
# specify constraints in INLA-ready format
constr.st <- list(A = A, e = rep(0, dim(A)[1]))
### defining Kronecker product for the Type III Interaction
# get scaled ICAR
scaled_ICAR_prec <- INLA::inla.scale.model(ICAR_structure,
constr = list(A = matrix(1,
1,
dim(ICAR_structure)[1]),
e = 0))
# Kronecker product between IID x ICAR
R <- diag(T) %x% scaled_ICAR_prec
typeIII_hyperparameters_priors = list(theta=list(prior="pc.prec",
param=c(1,0.01)))
#Model w. type III interaction
typeIII_formula <- update(basic_linear_formula,
~. + f(space_time_unstructured,
model = "generic0",
Cmatrix = R,
extraconstr = constr.st,
rankdef = T,
hyper = typeIII_hyperparameters_priors))
ptm <- Sys.time()
typeIII_fit <- inla(typeIII_formula,
data = ohio_df,
family = "poisson",
E = pop_at_risk,
control.compute = list(config = TRUE,
cpo = TRUE,
waic = TRUE))
time = Sys.time() - ptm
print(c("Number of constraints (should be 2 + 21 = 23): ",toString(typeIII_fit$misc$configs$constr$nc)))
print(c("-sum(log(CPO)): ", toString(round(-sum(log(typeIII_fit$cpo$cpo)), digits = 4))))
print(c("CPO failiure, should have 1 unique value",
toString(length(unique(typeIII_fit$cpo$failure))))) #-> soinla.cpo(res)
print(c("And that value is (should be 0): ", toString(typeIII_fit$cpo$failure[1])))
print(c("CPU: ", toString(summary(typeIII_fit)$cpu.used)))
print(c("Time: ", time))
#Check sum-to-zero constraints on interactions
interaction_mean <- typeIII_fit$summary.random$space_time_unstructured$mean
print(constr.st$A %*% interaction_mean)
check_sum_to_zero <- ifelse(constr.st$A %*% interaction_mean > 0 - 1E-10 &
constr.st$A %*% interaction_mean < 0 + 1E-10,
0,
1)
print(c("Number of counties for which sum-to-zero did not hold: ", toString(sum(check_sum_to_zero))))
#save type II cpo
typeIII_cpo_summary <- round(-sum(log(typeIII_fit$cpo$cpo)), digits = 4)
plot(typeIII_fit)
#Format results
temporal_effects_fitted <- data.frame(year = 1:T)
temporal_effects_fitted$q025_struct_effect <- typeIII_fit$summary.random$year$'0.025quant'[1:T]
temporal_effects_fitted$median_struct_effect <- typeIII_fit$summary.random$year$'0.5quant'[1:T]
temporal_effects_fitted$q975_struct_effect <- typeIII_fit$summary.random$year$'0.975quant'[1:T]
#
ggplot(data = temporal_effects_fitted) + ggtitle("Median structured Temporal effect") +
ylab("Temporal effect") +
geom_line(aes(x = year, y = q025_struct_effect), col = "red") +
geom_line(aes(x = year, y = q975_struct_effect), col = "blue") +
geom_ribbon(aes(x = year, ymin = q025_struct_effect, ymax = q975_struct_effect),
fill = "grey70") +
geom_line(aes(x = year, y = median_struct_effect)) +
xlim(1, 21)
######
#Plot the spatial effects
spatial_structured_effect_median <- typeIII_fit$summary.random$county$'0.5quant'[1:n]
spatial_structured_effect_q025 <- typeIII_fit$summary.random$county$'0.025quant'[1:n]
spatial_structured_effect_q975 <- typeIII_fit$summary.random$county$'0.975quant'[1:n]
spatial_structured_effect_sd   <- typeIII_fit$summary.random$county$sd[1:n]
temp_ohio_map <- ohio_map[ ,c("geometry", "NAME")]
temp_ohio_map$median <- spatial_structured_effect_median
temp_ohio_map$q025 <- spatial_structured_effect_q025
temp_ohio_map$q975 <- spatial_structured_effect_q975
temp_ohio_map$sd   <- spatial_structured_effect_sd
scale_col = heat.colors(30, rev=TRUE) #Divide color gradient into 30
scale_1 = scale_col[c(3,7,10,14,18,21,25,30)] #Select color scale to be more red
p_1 <- ggplot(data = temp_ohio_map) +
geom_sf(aes(fill = median),
alpha = 1,
color="black") + ggtitle("Median Spatial Structured Effect each County") +
theme(plot.title = element_text(size = 12),
axis.title.x = element_blank(), #Remove axis and background grid
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.background = element_blank(),
plot.margin =  unit(c(0, 0, 0, 0), "inches"),
legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
legend.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
panel.spacing = unit(1, 'lines')) +
guides(fill=guide_legend(title=NULL, reverse = TRUE, label.position = "right")) + #Remove colorbar title
binned_scale( #Scaling the color
aesthetics = "fill",
scale_name = "gradientn",
palette = function(x) c(scale_1),
labels = function(x){x},
guide = "colorscale")
#Plot median structured spatial effect in each county
#Side by side with median rate in each county
ggarrange(p_1, median_rate_plot,
ncol = 2, nrow = 1,
common.legend = FALSE)
ggplot(data = temp_ohio_map) +
geom_sf(aes(fill = sd),
alpha = 1,
color="black") + ggtitle("Standard Deviation of Spatial structured\n effect for each county") +
theme(plot.title = element_text(size = 20),
axis.title.x = element_blank(), #Remove axis and background grid
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.background = element_blank(),
plot.margin =  unit(c(0, 0, 0, 0), "inches"),
legend.box.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
legend.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
panel.spacing = unit(1, 'lines')) +
guides(fill=guide_legend(title=NULL, reverse = TRUE, label.position = "right")) + #Remove colorbar title
binned_scale( #Scaling the color
aesthetics = "fill",
scale_name = "gradientn",
palette = function(x) c(scale),
labels = function(x){x},
guide = "colorscale")
##Just the fitted values
#Extract fitted values
fitted_values <- data.frame(typeIII_fit$summary.fitted.values$mean)
#fitted values which is ???
colnames(fitted_values) <- "rate"
fitted_values$year <- ohio_df$year
fitted_values$county <- ohio_df$county
fitted_values$county_name <- ohio_df$county_name
fitted_values$to_sort_on <- ohio_df$space_time_unstructured
#Merge with geometry, this messes up order
fitted_values <- merge(ohio_map, fitted_values,
by.x = c("NAME"), by.y = c("county_name"),
all = T, suffixes = T)
#Sort on what is space_time_unstructured in ohio_df to get right order
fitted_values <- fitted_values[order(fitted_values$to_sort_on), ]
#Fix indices
rownames(fitted_values) <- 1:nrow(fitted_values)    # Assign sequence to row names
#Create heatmaps of the fitted values
p_1 <- case_count_plot_1_year(fitted_values, 1)
p_2 <- case_count_plot_1_year(fitted_values, 2)
p_3 <- case_count_plot_1_year(fitted_values, 3)
p_4 <- case_count_plot_1_year(fitted_values, 4)
p_5 <- case_count_plot_1_year(fitted_values, 5)
p_6 <- case_count_plot_1_year(fitted_values, 6)
p_7 <- case_count_plot_1_year(fitted_values, 7)
p_8 <- case_count_plot_1_year(fitted_values, 8)
p_9 <- case_count_plot_1_year(fitted_values, 9)
p_10 <- case_count_plot_1_year(fitted_values, 10)
p_11 <- case_count_plot_1_year(fitted_values, 11)
p_12 <- case_count_plot_1_year(fitted_values, 12)
p_13 <- case_count_plot_1_year(fitted_values, 13)
p_14 <- case_count_plot_1_year(fitted_values, 14)
p_15 <- case_count_plot_1_year(fitted_values, 15)
p_16 <- case_count_plot_1_year(fitted_values, 16)
p_17 <- case_count_plot_1_year(fitted_values, 17)
p_18 <- case_count_plot_1_year(fitted_values, 18)
p_19 <- case_count_plot_1_year(fitted_values, 19)
p_20 <- case_count_plot_1_year(fitted_values, 20)
p_21 <- case_count_plot_1_year(fitted_values, 21)
ggarrange(p_1, p_2, p_3, p_4,
p_5, p_6, p_7, p_8,
p_9, p_10, p_11, p_12,
p_13, p_14, p_15, p_16,
p_17, p_18, p_19, p_20,
p_21,
ncol = 5, nrow = 5,
common.legend = TRUE, legend = "right")
#The difference between the fitted values and actual values
#Make a copy to get same structure
fitted_values_copy = fitted_values
fitted_values_copy$rate = fitted_values_copy$rate - ohio_df$rate #abs()
min_diff_rate = min(fitted_values_copy$rate)
max_diff_rate = max(fitted_values_copy$rate)
hardcoded_bins_diff = round(seq(min_diff_rate, max_diff_rate, length.out = 8), 4)
p_1 <- case_count_plot_1_year(fitted_values_copy, 1, hardcoded_bins = hardcoded_bins_diff)
p_2 <- case_count_plot_1_year(fitted_values_copy, 2, hardcoded_bins = hardcoded_bins_diff)
p_3 <- case_count_plot_1_year(fitted_values_copy, 3, hardcoded_bins = hardcoded_bins_diff)
p_4 <- case_count_plot_1_year(fitted_values_copy, 4, hardcoded_bins = hardcoded_bins_diff)
p_5 <- case_count_plot_1_year(fitted_values_copy, 5, hardcoded_bins = hardcoded_bins_diff)
p_6 <- case_count_plot_1_year(fitted_values_copy, 6, hardcoded_bins = hardcoded_bins_diff)
p_7 <- case_count_plot_1_year(fitted_values_copy, 7, hardcoded_bins = hardcoded_bins_diff)
p_8 <- case_count_plot_1_year(fitted_values_copy, 8, hardcoded_bins = hardcoded_bins_diff)
p_9 <- case_count_plot_1_year(fitted_values_copy, 9, hardcoded_bins = hardcoded_bins_diff)
p_10 <- case_count_plot_1_year(fitted_values_copy, 10, hardcoded_bins = hardcoded_bins_diff)
p_11 <- case_count_plot_1_year(fitted_values_copy, 11, hardcoded_bins = hardcoded_bins_diff)
p_12 <- case_count_plot_1_year(fitted_values_copy, 12, hardcoded_bins = hardcoded_bins_diff)
p_13 <- case_count_plot_1_year(fitted_values_copy, 13, hardcoded_bins = hardcoded_bins_diff)
p_14 <- case_count_plot_1_year(fitted_values_copy, 14, hardcoded_bins = hardcoded_bins_diff)
p_15 <- case_count_plot_1_year(fitted_values_copy, 15, hardcoded_bins = hardcoded_bins_diff)
p_16 <- case_count_plot_1_year(fitted_values_copy, 16, hardcoded_bins = hardcoded_bins_diff)
p_17 <- case_count_plot_1_year(fitted_values_copy, 17, hardcoded_bins = hardcoded_bins_diff)
p_18 <- case_count_plot_1_year(fitted_values_copy, 18, hardcoded_bins = hardcoded_bins_diff)
p_19 <- case_count_plot_1_year(fitted_values_copy, 19, hardcoded_bins = hardcoded_bins_diff)
p_20 <- case_count_plot_1_year(fitted_values_copy, 20, hardcoded_bins = hardcoded_bins_diff)
p_21 <- case_count_plot_1_year(fitted_values_copy, 21, hardcoded_bins = hardcoded_bins_diff)
ggarrange(p_1, p_2, p_3, p_4,
p_5, p_6, p_7, p_8,
p_9, p_10, p_11, p_12,
p_13, p_14, p_15, p_16,
p_17, p_18, p_19, p_20,
p_21,
ncol = 5, nrow = 5,
common.legend = TRUE, legend = "right")
#Relative deviation
fitted_values_copy$rate = ifelse(ohio_df$rate == 0,
(fitted_values$rate)/0.0001,
abs((fitted_values$rate - ohio_df$rate)/ohio_df$rate))
min_diff_rate = min(fitted_values_copy$rate)
max_diff_rate = max(fitted_values_copy$rate)
#hardcoded_bins_diff = round(seq(min_diff_rate, max_diff_rate, length.out = 8), 4)
hardcoded_bins_diff = seq(0, 1, length.out = 8)
p_1 <- case_count_plot_1_year(fitted_values_copy, 1, hardcoded_bins = hardcoded_bins_diff)
p_2 <- case_count_plot_1_year(fitted_values_copy, 2, hardcoded_bins = hardcoded_bins_diff)
p_3 <- case_count_plot_1_year(fitted_values_copy, 3, hardcoded_bins = hardcoded_bins_diff)
p_4 <- case_count_plot_1_year(fitted_values_copy, 4, hardcoded_bins = hardcoded_bins_diff)
p_5 <- case_count_plot_1_year(fitted_values_copy, 5, hardcoded_bins = hardcoded_bins_diff)
p_6 <- case_count_plot_1_year(fitted_values_copy, 6, hardcoded_bins = hardcoded_bins_diff)
p_7 <- case_count_plot_1_year(fitted_values_copy, 7, hardcoded_bins = hardcoded_bins_diff)
p_8 <- case_count_plot_1_year(fitted_values_copy, 8, hardcoded_bins = hardcoded_bins_diff)
p_9 <- case_count_plot_1_year(fitted_values_copy, 9, hardcoded_bins = hardcoded_bins_diff)
p_10 <- case_count_plot_1_year(fitted_values_copy, 10, hardcoded_bins = hardcoded_bins_diff)
p_11 <- case_count_plot_1_year(fitted_values_copy, 11, hardcoded_bins = hardcoded_bins_diff)
p_12 <- case_count_plot_1_year(fitted_values_copy, 12, hardcoded_bins = hardcoded_bins_diff)
p_13 <- case_count_plot_1_year(fitted_values_copy, 13, hardcoded_bins = hardcoded_bins_diff)
p_14 <- case_count_plot_1_year(fitted_values_copy, 14, hardcoded_bins = hardcoded_bins_diff)
p_15 <- case_count_plot_1_year(fitted_values_copy, 15, hardcoded_bins = hardcoded_bins_diff)
p_16 <- case_count_plot_1_year(fitted_values_copy, 16, hardcoded_bins = hardcoded_bins_diff)
p_17 <- case_count_plot_1_year(fitted_values_copy, 17, hardcoded_bins = hardcoded_bins_diff)
p_18 <- case_count_plot_1_year(fitted_values_copy, 18, hardcoded_bins = hardcoded_bins_diff)
p_19 <- case_count_plot_1_year(fitted_values_copy, 19, hardcoded_bins = hardcoded_bins_diff)
p_20 <- case_count_plot_1_year(fitted_values_copy, 20, hardcoded_bins = hardcoded_bins_diff)
p_21 <- case_count_plot_1_year(fitted_values_copy, 21, hardcoded_bins = hardcoded_bins_diff)
ggarrange(p_1, p_2, p_3, p_4,
p_5, p_6, p_7, p_8,
p_9, p_10, p_11, p_12,
p_13, p_14, p_15, p_16,
p_17, p_18, p_19, p_20,
p_21,
ncol = 5, nrow = 5,
common.legend = TRUE, legend = "right")
A[1, ]
A[2, ]
constr.st$e
?control.predictor
libPaths()
.libPaths()
