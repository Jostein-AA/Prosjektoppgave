---
title: "Simple_simulations"
author: "Jostein Aasteboel, Aanes and 10920007"
date: "2023-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#Load libraries
library(INLA)
library(tidyverse)
library(spData)
library(sf)
library(spdep)
library(ggplot2)
require(mgcv)
library(MASS)
library(fastmatrix)
library(rwc)
```

```{r load_map}
#Define columns to keep
columns_to_keep <- c("AREA", "PERIMETER", "POLYID", "NEIG", "DISCBD",
                     "X", "Y", "NEIGNO", "geometry")

# read a shapefile, defining the country and subregional borders
map <- st_read(system.file("shapes/columbus.shp",
                           package = "spData"), quiet = TRUE)


#Only keep columns as written
map <- map[, columns_to_keep]

# extract the adjacency structure from the graph: map.
# queen = FALSE, since it is closer to being rook adjacency.
nb <- spdep::poly2nb(map, queen = FALSE)

# Create adjacency matrix, needed as structure matrix for ICAR
adjacency_matrix <- nb2mat(nb, style="B")
mydiag = rowSums(adjacency_matrix)
adjacency_matrix <- -adjacency_matrix
diag(adjacency_matrix) <- mydiag

#Sanity check: If adjacency_matrix is correct both rows and columns should all sum-to-zero
print("rows sum-to-zero:")
print((length(unique(apply(adjacency_matrix, 1, sum))) == 1 & apply(adjacency_matrix, 1, sum)[1] == 0))

print("columns sum-to-zero:")
print((length(unique(apply(adjacency_matrix, 2, sum))) == 1 & apply(adjacency_matrix, 2, sum)[1] == 0))
```

```{r preliminaries}
# Define over how many time points to simulate data from 
T = 15
time <- 1:T

# Extract number of regions
n = length(nb)

#Define the zero mean vector for the temporal dimension
zero_vector_T = rep(0, T)

#Define the zero mean vector for the spatial dimension
zero_vector_n= rep(0, n)

#Define the zero vector for the interaction-space
zero_vector_interaction = rep(0, n * T)

#Define the identity matrix for Temporal dimension: TxT
I_T = diag(1, T, T)

#Define identity matrix I_n, dimension nxn
I_n = diag(1, nrow = n, ncol = n)
```

```{r define_precision_matrices_of_effects}
# precision matrix of gamma
Q_gamma = 0.5 * I_T

#Define structure matrix for alpha, structure as RW1
K_alpha <- INLA:::inla.rw(n = T, order = 1, 
                           scale.model = F, # set scale.model = F
                           sparse = F)

# Precision matrix of alpha
Q_alpha = K_alpha

# Precision matrix phi
Q_phi = 0.5 * I_n

# Precision matrix theta
Q_theta = adjacency_matrix

```


```{r sample_effects}
#Sample the effects present in the linear predictor

set.seed(507740)
mu = rnorm(1, mean = 0, sd = 1)    # mu

gamma = rnorm.Q(Q_gamma,                  # Precision matrix gamma
                mu = zero_vector_T,       # Prior mean gamma (0,..,0)
                X = Matrix(1, nrow = nrow(Q_gamma), ncol = 1), #Defines a vector which samples are orthogonal too
                zero.constraint = TRUE                         # Make it so samples are orthogonal to (1,...,1)
                ) 

alpha = rnorm.Q(Q_alpha,                  # Precision matrix alpha
                mu = zero_vector_T,       # Prior mean alpha (0,..,0)
                X = Matrix(1, nrow = nrow(Q_alpha), ncol = 1), #Defines a vector which samples are orthogonal too
                zero.constraint = TRUE                         # Make it so samples are orthogonal to (1,...,1)
                ) 

phi = rnorm.Q(Q_phi,                  # Precision matrix phi
                mu = zero_vector_n,       # Prior mean phi (0,..,0)
                X = Matrix(1, nrow = nrow(Q_phi), ncol = 1), #Defines a vector which samples are orthogonal too
                zero.constraint = TRUE                         # Make it so samples are orthogonal to (1,...,1)
                ) 


theta = rnorm.Q(Q_theta,                  # Precision matrix theta
                mu = zero_vector_n,       # Prior mean theta (0,..,0)
                X = Matrix(1, nrow = nrow(Q_theta), ncol = 1), #Defines a vector which samples are orthogonal too
                zero.constraint = TRUE                         # Make it so samples are orthogonal to (1,...,1)
                )
```

```{r precision_matr_interactions}

# structure/precision matrices
delta.prec.I <-   kronecker.prod(I_T, y = I_n)                     #Structure matrix, here used as precision
delta.prec.II <-  kronecker.prod(K_alpha, y = I_n)                 # --||--
delta.prec.III <- kronecker.prod(I_T, y = adjacency_matrix)        # --||--
delta.prec.IV <-  kronecker.prod(K_alpha, y = adjacency_matrix)    # --||--
```

```{r constraints_interactions}
# Define constraint matrices for type II-IV interactions for sampling

# Constraint-matrix for type-II interaction
constraint.II <- matrix(0, nrow = nrow(delta.prec.II), ncol = n)
for (i in 1:n) { 
  #???
  constraint.II[which((1:(n * T))%%n == i - 1), i] <- 1
}

constraint.III <- matrix(0, nrow = nrow(delta.prec.III), ncol = T)
for (i in 1:T) {
  # The ICAR at each time point needs to sum to ?1?
  constraint.III[((i - 1) * n + 1):(i * n), i] <- 1
}


# Specifying constraints needed for Type IV Interaction
time_constr <- matrix(0, n * T, n)
for (i in 1:n) {
  time_constr[which((1:(n * T))%%n == i - 1), i] <- 1
}
space_constr <- matrix(0, n * T, T-1)
# theoretically it's enough to only go through N-1 here
# note that we could have instead done 1:(S-1) in the first loop and 1:N in the second
for (i in 1:(T-1)) { 
  space_constr[((i - 1) * n + 1):(i * n), i] <- 1
}

constraint.IV <- cbind(time_constr, space_constr) 
```


```{r sample_interactions}
#Sample interactions of type I - IV:
set.seed(507741)
delta.I = rnorm.Q(delta.prec.I,                  # Precision matrix delta.I
                mu = zero_vector_interaction       # Prior mean delta.I (0,..,0)
                )                                  

delta.II = rnorm.Q(delta.prec.II,                  # Precision matrix delta.II
                mu = zero_vector_interaction,      # Prior mean delta.II (0,..,0)
                X = constraint.II,                 # Constraint matrix samples are orthogonal to
                zero.constraint = T                # Make it so samples are orthogonal to constraint.II
                )

delta.III = rnorm.Q(delta.prec.III,                  # Precision matrix delta.III
                mu = zero_vector_interaction,       # Prior mean delta.III (0,..,0)
                X = constraint.III, 
                zero.constraint = T            # Make it so samples are orthogonal to (1,...,1)
                )

delta.IV = rnorm.Q(delta.prec.IV,                  # Precision matrix delta.IV
                mu = zero_vector_interaction,       # Prior mean delta.IV (0,..,0)
                X = constraint.IV, 
                zero.constraint = TRUE            # Make it so samples are orthogonal to (1,...,1)
                )
```


```{r define_linear_predictor}
#Initiate memory for linear predictors
eta    = matrix(0, T, n); eta.I = matrix(0, T, n)
eta.II = matrix(0, T, n); eta.III = matrix(0, T, n)
eta.IV = matrix(0, T, n)

# Get the values for the linear predictor at every time point at every area 
for(t in 1:T){
  for(i in 1:n){
    eta[t, i] = mu + alpha[t] + gamma[t] + theta[i] + phi[i]
    eta.I[t, i] = mu + alpha[t] + gamma[t] + theta[i] + phi[i] + delta.I[t * i]
    eta.II[t, i] = mu + alpha[t] + gamma[t] + theta[i] + phi[i] + delta.II[t * i]
    eta.III[t, i] = mu + alpha[t] + gamma[t] + theta[i] + phi[i] + delta.III[t * i]
    eta.IV[t, i] = mu + alpha[t] + gamma[t] + theta[i] + phi[i] + delta.IV[t * i]
  }
}
```

```{r sample_Binomial_response}
#Binomial logit link p = exp(eta)/(1+exp(eta))
p = exp(eta)/(1 + exp(eta)); p.I = exp(eta.I)/(1 + exp(eta.I))
p.II = exp(eta.II)/(1 + exp(eta.II)); p.III = exp(eta.III)/(1 + exp(eta.III))
p.IV = exp(eta.IV)/(1 + exp(eta.IV))

#Initiate memory for responses
y_binom = matrix(0, T, n); y_binom.I = matrix(0, T, n)
y_binom.II = matrix(0, T, n); y_binom.III = matrix(0, T, n)
y_binom.IV = matrix(0, T, n)


#Sample responses from Binomial
set.seed(507742)
for(t in 1:T){
  for(i in 1:n){
    y_binom[t, i]     = rbinom(n = 1, 10000, p[t, i])
    y_binom.I[t, i]   = rbinom(n = 1, 10000, p.I[t, i])
    y_binom.II[t, i]  = rbinom(n = 1, 10000, p.II[t, i])
    y_binom.III[t, i] = rbinom(n = 1, 10000, p.III[t, i])
    y_binom.IV[t, i]  = rbinom(n = 1, 10000, p.IV[t, i])
  }
}

```

```{r heat_map}

map$disease <- y_binom.IV[4,]

plot(map['disease'])
```

```{r basic_lin_predictor}
#Basic linear predictor, alpha assumed RW1
basic_lin_pred <- deaths ~ 1 + f(year, model = "bym2", scale.model = T, 
                                 constr = T, rankdef = 1, graph = K_alpha,
                                 hyper = list(
                                      phi = list(
                                        prior = "pc",
                                        param = c(0.5, 2/3)), #Magic number
                                      prec = list(
                                        prior = "pc.prec",
                                        param = c(1, 0.01)) #Magic number
                                      )
                                 ) + 
                                f(county, model = "bym2", scale.model = T,
                                  constr = T, rankdef = 1, graph = adjacency_matrix,
                                  hyper = list(
                                    phi = list(
                                      prior = "pc",
                                      param = c(0.5, 2/3) #Magic number
                                    ),
                                    prec = list(
                                      prior = "pc.prec",
                                      param = c(1, 0.01) #Magic number
                                    )
                                  ))
```

```{r fit_basic_model}
basic_fit <- inla(basic_linear_predictor,
                 data = ohio_df,
                 family = "poisson",
                 E = expected,
                 control.compute = list(config = TRUE)) # needed if you want to see constraints later



```


```{r}
print("done diddyli doo")
```

```{r}
#Poisson link
lambda = exp(eta)

#Sample responses from Poisson
y_poisson = matrix(0, T, n)
set.seed(507743)
for (t in 1:T) {
  for (i in 1:n) {
    y_poisson[t, i] = rpois(n = 1, lambda[t, i])
  }
}
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```